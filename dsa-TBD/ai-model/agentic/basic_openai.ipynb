{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4cd1945-c4a5-4535-8240-709f0ca1f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env existist: REMOVED_SECRET\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    env_exist=os.environ.get(var)\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "    else:\n",
    "        print(f\"env existist: {env_exist}\")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79be9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "try:\n",
    "    with open(\"nginx_metrics_compact.json\", \"r\") as compact_file:\n",
    "        existing_summary = json.load(compact_file)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"nginx_metrics_compact.json not found\")\n",
    "# LLM prompt\n",
    "prompt = f\"\"\"\n",
    "Analyze the following NGINX ingress metrics:\n",
    "\n",
    "Metrics Summary:\n",
    "{json.dumps(existing_summary, indent=2)}\n",
    "\n",
    "Based on the patterns over the last 5m, 1h, 3h, 6h, 12h, 1d, 3d, and 7d, recommend if the load balancing algorithm should be changed. Provide reasons for your recommendation.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "032b7958-aa3a-474e-8ee6-b470c2c12f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0b6da0-680b-491b-bf1a-1cf132b33e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on the provided NGINX ingress metrics, it appears that there is no traffic being processed by the system. The request count is consistently zero across all time intervals (5m, 1h, 3h, 6h, 12h, 1d, 3d, and 7d). Additionally, the average response time and the 95th percentile response time are also zero or NaN, indicating no requests are being handled. There are no active or dropped connections recorded in any of the time intervals.\\n\\nGiven this data, there is no evidence of load or traffic that would necessitate a change in the load balancing algorithm. The current metrics suggest that the system is either not receiving any traffic or is not correctly capturing the traffic data. \\n\\nHere are the reasons for not recommending a change in the load balancing algorithm:\\n\\n1. **No Traffic Detected**: The request count is zero across all time frames, indicating that there is no load to balance. Without traffic, the effectiveness of the load balancing algorithm cannot be assessed.\\n\\n2. **No Performance Issues**: With no active connections or requests, there are no performance issues such as high response times or dropped connections that would suggest a need for a different load balancing strategy.\\n\\n3. **Data Collection Issues**: The consistent zero values and NaN for response times might indicate a problem with data collection or monitoring setup rather than an issue with the load balancing itself.\\n\\nBefore considering any changes to the load balancing algorithm, it would be prudent to verify the monitoring setup to ensure that it is correctly capturing traffic data. If the system is expected to handle traffic, further investigation is needed to determine why no traffic is being recorded. If the system is intentionally idle, then no changes are necessary.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 356, 'prompt_tokens': 2435, 'total_tokens': 2791, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-7e60da42-de4a-4d33-b3ce-5f0adbff62fd-0', usage_metadata={'input_tokens': 2435, 'output_tokens': 356, 'total_tokens': 2791, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\" Analyze the following NGINX ingress metrics and recommend if the load balancing algorithm should be changed. \n",
    "            Provide clear reasons for your recommendation based on the metrics patterns.\"\"\"\n",
    "    ),\n",
    "    (\"human\", prompt),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6809c5c9-a314-48af-ba53-33c58e7bf94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow in future\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91f3b8e8-638a-4fec-b3f8-210862e1a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "planner = planner_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o\", temperature=0\n",
    ").with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ce6d6bc-0770-4937-8ea2-dd3d49e89788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plan(steps=['Identify your personal and professional goals for the next year.', 'Break down each goal into smaller, manageable tasks.', 'Set a timeline for each task, ensuring they are realistic and achievable.', 'Prioritize tasks based on importance and deadlines.', 'Allocate resources and time for each task.', 'Monitor progress regularly and adjust the plan as needed.', 'Celebrate achievements and learn from any setbacks.'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"What should be my plans for next year ?\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92e9f4-fdeb-4428-8627-91418e71f4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2920514-b34a-47d6-b081-13e1e03c727a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
