{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4cd1945-c4a5-4535-8240-709f0ca1f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env existist: sk-proj-s246J7yBjSnfvFDjS5sbT3BlbkFJy5ml8zJ7CBGZGidVmWu8\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    env_exist=os.environ.get(var)\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "    else:\n",
    "        print(f\"env existist: {env_exist}\")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"nginx_metrics_compact.json\", \"r\") as compact_file:\n",
    "        existing_summary = json.load(compact_file)\n",
    "        compact_summary.update(existing_summary)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"nginx_metrics_compact.json not found\")\n",
    "# LLM prompt\n",
    "prompt = f\"\"\"\n",
    "Analyze the following NGINX ingress metrics:\n",
    "\n",
    "Metrics Summary:\n",
    "{json.dumps(existing_summary, indent=2)}\n",
    "\n",
    "Based on the patterns over the last 5m, 1h, 3h, 6h, 12h, 1d, 3d, and 7d, recommend if the load balancing algorithm should be changed. Provide reasons for your recommendation.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "032b7958-aa3a-474e-8ee6-b470c2c12f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f0b6da0-680b-491b-bf1a-1cf132b33e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 28, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_5f20662549', 'finish_reason': 'stop', 'logprobs': None}, id='run-005b927b-2054-402a-8b94-ffcba5d1acd8-0', usage_metadata={'input_tokens': 28, 'output_tokens': 6, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\" Analyze the following NGINX ingress metrics and recommend if the load balancing algorithm should be changed. \n",
    "            Provide clear reasons for your recommendation based on the metrics patterns.\"\"\"\n",
    "    ),\n",
    "    (\"human\", prompt),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6809c5c9-a314-48af-ba53-33c58e7bf94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow in future\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91f3b8e8-638a-4fec-b3f8-210862e1a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "planner = planner_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o\", temperature=0\n",
    ").with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ce6d6bc-0770-4937-8ea2-dd3d49e89788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plan(steps=['Identify your personal and professional goals for the next year.', 'Break down each goal into smaller, manageable tasks.', 'Set a timeline for each task, ensuring they are realistic and achievable.', 'Prioritize tasks based on importance and deadlines.', 'Allocate resources and time for each task.', 'Monitor progress regularly and adjust the plan as needed.', 'Celebrate achievements and learn from any setbacks.'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"What should be my plans for next year ?\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92e9f4-fdeb-4428-8627-91418e71f4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2920514-b34a-47d6-b081-13e1e03c727a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
